{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35980f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "num_points = 20\n",
    "radius = 8.00\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f0813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Play a notification sound\n",
    "notification_sound = \"program_completed.wav\"  # Replace with the actual audio file name\n",
    "os.system(f\"afplay {notification_sound}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a06ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "# # -----------1. 2.  3. 4.  5. 6. 7. 8.  9.  10. 11. 12. 13.  14.  15. 16. 17. 18.  19. 20.\n",
    "# x_coords = [-5, 7, 7,-11,-1 ,1, 4, 14, 12, -13, 12, -7, 14, -14, -5, -10, 5 , -13,  3, 10 ]\n",
    "# y_coords = [-7, 4,-9,-1 ,-11,8,-6, 13, 3 , -10, -3,  7, 6 , -4 ,  2, -2 , 13,  5 , -2, 2 ]\n",
    "\n",
    "\n",
    "# # arrangement after 5 nodes move (nodes 8, 9, 13,16, 20).\n",
    "# # -----------1 2  3  4   5  6  7  8   9    10  11  12  13   14   15. 16 17  18  19 20\n",
    "# x_coords = [-5,7, 7,-11,-1 ,1, 4, 10, 10, -13, 12, -7, 15, -14, -5, -5, 5, -13, 3, 12 ]\n",
    "# y_coords = [-7,4,-9,-1 ,-11,8,-6, 13, 10,  -10, -3,  7, 6 , -4,   2, -2,13, 5, -2, 0 ]\n",
    "\n",
    "# # arrangement after 5 nodes move (nodes 9, 8, 13,16, 20).\n",
    "# # -----------1 2  3  4   5  6  7  8   9    10  11  12  13   14   15. 16 17  18  19 20\n",
    "# x_coords = [-5,7, 7,-11,-1 ,1, 4, 10, 10, -13, 12, -7, 15, -14, -5, -5, 5, -13, 3, 12 ]\n",
    "# y_coords = [-7,4,-9,-1 ,-11,8,-6, 13, 10,  -10, -3,  7, 6 , -4,   2, -2,13, 5, -2, 0 ]\n",
    "\n",
    "# # arrangment3\n",
    "\n",
    "# x_coords = [-8, 3,  5, 14, 2,  3,  8, -12,   0, -8, -15, -13, -12, 11,  1, -12, -2, -3,  7,  2]\n",
    "# y_coords = [-9, 7, -5,  9, 3, 13, 14, -10, -12,  7,  -4, -13,  -3, -3, -1,  -1,  2, 10, 10, -11]\n",
    "\n",
    "# # arrangment 3 nodes moved   5, 13, 20\n",
    "\n",
    "# x_coords = [-8, 3,  5, 14, 10,  3, 8,  -12,  0,  -8, -15, -13, -5, 11,  1, -12, -2, -3,  7,  0]\n",
    "# y_coords = [-9, 7, -5,  9,  5, 13, 14, -10, -12,  7,  -4, -13, -3, -3, -1,  -1,  2, 10, 10, -5]\n",
    "\n",
    "# # arrangement 4\n",
    "# x_coords = [15, 11, -8, -11, 8 , -11, -3, -5, 15, -9, -1, -5, 13, -3, 4, -5, -4,  2,  5, 6 ]\n",
    "# y_coords = [9,  6, -14, -10, -1, -6 , 0 , -5, -6, 1 , 8 , 11, 0, 15, 12, 8,  5, -1, -5, -11]\n",
    "\n",
    "# # arrangment4  nodes moved 3, 9, 16 \n",
    "# x_coords = [15, 11,  0, -11,  8, -11, -3, -5, 10, -9, -1, -5, 13, -3, 4, 5, -4,  2,  5,  6 ]\n",
    "# y_coords = [ 9,  6, -5, -10, -1, -6 , 0 , -5, -5, 1 , 8 , 11, 0, 15, 12, 5,  5, -1, -5, -11]\n",
    "\n",
    "# # other\n",
    "# x_coords = [10, 12, 9,  0, -5,  4, -13, -13, 14, 0, -14,  -2, -12, -2,  -6, 2, 5, -8, 14, -6]\n",
    "# y_coords = [-8, -8, 0, -3,  3, -6,   0,  -4,  4, 5, -10, -13, -11, -8, -12, 0, 5, -6, -2, 7]\n",
    "\n",
    "\n",
    "#scenario1  1.   2    3    4   5    6   7.  8.  9.  10  11 12  13. 14. 15  16. 17. 18  19   20\n",
    "x_coords = [15, 11,  -8, -11,  8, -11, -3, -5, 15, -9, -1, -5, 13, -3,  4, -5, -4,  2,  5,   6]\n",
    "y_coords = [ 9,  6, -14, -10, -1,  -6,  0, -5, -6,  1,  8, 11,  0, 15, 12,  8,  5, -1, -5, -11]\n",
    "\n",
    "\n",
    "\n",
    "point_labels = [f\"P{i + 1}\" for i in range(num_points)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd372fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "points = [(x_coords[i], y_coords[i]) for i in range(num_points)]\n",
    "\n",
    "distances = pdist(points)\n",
    "\n",
    "dist_matrix = squareform(distances)\n",
    "\n",
    "dist_matrix = pd.DataFrame(dist_matrix, columns = point_labels, index = point_labels)\n",
    "\n",
    "\n",
    "dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189f320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_table = dist_matrix\n",
    "neighbor_table = neighbor_table.applymap(lambda x : 1000000 if x > radius else 1)\n",
    "\n",
    "for i in range(num_points):\n",
    "    neighbor_table.at[f\"P{i + 1}\", f\"P{i + 1}\"] = 0\n",
    "    \n",
    "neighbor_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48efa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "# function to select 60% of nodes requesting to transmit their messages.\n",
    "def select_nodes():\n",
    "    nodes = [random.uniform(0,1) for _ in range(num_points + 1)]\n",
    "    \n",
    "    nodes = [0 if v < 0.4 else 1 for v in nodes]\n",
    "    \n",
    "    nodes[0] = 0  #X[0] is default 0 to make 1-based indexing\n",
    "    \n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf3265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "selected = select_nodes()      # testing the function\n",
    "print(selected)\n",
    "\n",
    "# dest = [0 for i in range (num_points + 1)]\n",
    "# print(dest)\n",
    "    \n",
    "# selected_nodes = [i for i, x in enumerate(X_vec) if x == 1]\n",
    "# print(selected_nodes)\n",
    "\n",
    "# node = 0\n",
    "\n",
    "# neighbors = np.array(neighbor_table.loc[f\"P{node}\"])\n",
    "# print(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c6595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# function to select destination nodes, for the nodes which want to transmit\n",
    "def select_destinations(X_vec):\n",
    "    \n",
    "    dest = [0 for i in range (num_points + 1)]\n",
    "    \n",
    "    selected_nodes = [i for i, x in enumerate(X_vec) if x == 1]\n",
    "    \n",
    "    \n",
    "    for node in selected_nodes:\n",
    "        neighbors = np.array(neighbor_table.loc[f\"P{node}\"])\n",
    "        neighbor_indices = np.where(neighbors == 1)[0]\n",
    "        if len(neighbor_indices) > 0:\n",
    "            random_neighbor = np.random.choice(neighbor_indices) + 1\n",
    "            dest[node] = random_neighbor\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "    return dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70b58ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations = select_destinations(selected)  #testing the function\n",
    "print(destinations)\n",
    "\n",
    "# temp_indexes = [i for i, num in enumerate(destinations) if num > 0]\n",
    "# print(temp_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361e646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_c3(dst, neighbor):\n",
    "    constraint = []\n",
    "    \n",
    "    for i in range(len(dst)):\n",
    "        str = []\n",
    "        \n",
    "        if(dst[i] > 0): \n",
    "            ind = dst[i]\n",
    "            \n",
    "            str.append(ind)   #destination can't transmit also\n",
    "            \n",
    "            for j in range(num_points):\n",
    "                if(neighbor[f\"P{ind}\"][f\"P{j + 1}\"] == 1 and j != i - 1):\n",
    "                    str.append(j + 1)\n",
    "                    \n",
    "            constraint.append(str)\n",
    "            \n",
    "        else:\n",
    "            constraint.append('')\n",
    "        \n",
    "    return  constraint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5049f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "C3 = define_c3(destinations, neighbor_table)\n",
    "C3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b30dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import itertools\n",
    "\n",
    "def solve_instance(d, c):          #updated the parameters\n",
    "    \n",
    "    indexes = [i for i, num in enumerate(d) if num > 0]\n",
    "    combinations = []\n",
    "    result = None\n",
    "    unique_combinations = []\n",
    "    \n",
    "      \n",
    "    for size in range(len(indexes), 0, -1):\n",
    "        #genetating all combination such that any 1 node finally transmits , or 2 nodes and so on.\n",
    "        #and these combinations will be checked if they satisfy the constraints\n",
    "        combinations = itertools.combinations(indexes, size)\n",
    "        \n",
    "               \n",
    "        for combination in combinations:\n",
    "            valid_comb = True\n",
    "            for elem in combination:          # EACH element of combination should satisfy the consrtaints\n",
    "                intersection = set(c[elem]).intersection(set(combination))\n",
    "                if(len(intersection) > 0):\n",
    "                    valid_comb = False\n",
    "                    break\n",
    "                              \n",
    "            \n",
    "            if(valid_comb):                            #for stopping the loop when valid combination found\n",
    "                result = combination\n",
    "                break  \n",
    "            \n",
    "                       \n",
    "        if(result != None and len(result) > 0):    #for stopping the loop when valid combination found\n",
    "            break\n",
    "                        \n",
    "                  \n",
    "    return list(result)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e8b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def generate_data(rows):\n",
    "    \n",
    "    #data = pd.DataFrame(columns=['Instance', 'Solution'], index=[i for i in range(rows)])\n",
    "    \n",
    "    data_X = []\n",
    "    data_y = []\n",
    "#     df.loc[0, 'X'] = X\n",
    "#     df.loc[0, 'Y'] = Y\n",
    "    \n",
    "    for i in range(rows):\n",
    "        X = select_nodes()\n",
    "        \n",
    "        print(i, end= \" \")\n",
    "        D = select_destinations(X)\n",
    "        #D = [0, 5, 0, 11, 16, 1, 2, 3, 13, 13, 14, 0, 15, 9, 0, 16, 14, 6, 4, 2, 11]\n",
    "        #print(f\" D is {D}\")\n",
    "        C3 = define_c3(D, neighbor_table)\n",
    "        #print(f\"C3  {C3}\")\n",
    "        \n",
    "        sol = solve_instance(D,C3)\n",
    "        #print(f\" sol is {sol}\")\n",
    "        \n",
    "        #data.at[i, 'Instance'] = make_dictionary(X, D) #for representing input as dictionary\n",
    "        \n",
    "        data_X.append(D[1:])\n",
    "        #data.at[i, 'Instance'] = D[1:]\n",
    "        \n",
    "        \n",
    "        y_var = [0 for i in range (num_points)]\n",
    "        \n",
    "        for j in sol:\n",
    "            y_var[j - 1] = 1\n",
    "            \n",
    "        data_y.append(y_var)\n",
    "        \n",
    "        #data.at[i, 'Solution'] = sol\n",
    "               \n",
    "    \n",
    "    x_var = np.array(data_X)\n",
    "    y_var = np.array(data_y)\n",
    "    \n",
    "    return x_var, y_var\n",
    "\n",
    "os.system(f\"afplay {notification_sound}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5067a40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_set1_1, y_set1_1 = generate_data(20000)\n",
    "# os.system(f\"afplay {notification_sound}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef545936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_set2_1, y_set2_1 = generate_data(20000)\n",
    "# os.system(f\"afplay {notification_sound}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8480e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_set3_1, y_set3_1 = generate_data(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadf769a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_set4_1, y_set4_1 = generate_data(20000)\n",
    "# os.system(f\"afplay {notification_sound}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1c786f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_set5_1, y_set5_1 = generate_data(20000)\n",
    "# os.system(f\"afplay {notification_sound}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6323232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # saving the partial datasets\n",
    "# np.save('X_set1_2.npy', X_set1_2)\n",
    "# np.save('X_set2_2.npy', X_set2_2)\n",
    "# np.save('X_set3_2.npy', X_set3_2)\n",
    "# np.save('X_set4_2.npy', X_set4_2)\n",
    "# np.save('X_set5_2.npy', X_set5_2)\n",
    "# np.save('y_set1_2.npy', y_set1_2)\n",
    "# np.save('y_set2_2.npy', y_set2_2)\n",
    "# np.save('y_set3_2.npy', y_set3_2)\n",
    "# np.save('y_set4_2.npy', y_set4_2)\n",
    "# np.save('y_set5_2.npy', y_set5_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9516d659",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_set1_2, y_set1_2 = generate_data(20000)\n",
    "# X_set2_2, y_set2_2 = generate_data(20000)\n",
    "# X_set3_2, y_set3_2 = generate_data(20000)\n",
    "# X_set4_2, y_set4_2 = generate_data(20000)\n",
    "# X_set5_2, y_set5_2 = generate_data(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2b66d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_set_1, y_set_1  = generate_data(200000)\n",
    "# os.system(f\"afplay {notification_sound}\")\n",
    "\n",
    "# X_test_1, y_test_1  = generate_data(50000)\n",
    "# os.system(f\"afplay {notification_sound}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1fffb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "display(X_set_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596b8479",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "display(y_set_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ed5b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(y_set_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f20124",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_set_2, y_set_2 = generate_data(200000)\n",
    "os.system(f\"afplay {notification_sound}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9f63c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_test_2, y_test_2 = generate_data(50000)\n",
    "# os.system(f\"afplay {notification_sound}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef34209a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # X_test_new, y_test_new = generate_data(50000)\n",
    "# X_set_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2fa576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine arrays along axis 0 (vertical stacking)\n",
    "# X_set_2 = np.concatenate((X_set1_new, X_set2_new, X_set3_new, X_set4_new, X_set5_new), axis=0)\n",
    "X_set_2 = np.concatenate((X_set_1, X_set_2), axis=0)\n",
    "y_set_2 = np.concatenate((y_set_1, y_set_2), axis=0)\n",
    "\n",
    "# print(X_set_2.shape)\n",
    "\n",
    "# # Combine arrays along axis 0 (vertical stacking)\n",
    "# y_set_2 = np.concatenate((y_set1_new, y_set2_new, y_set3_new, y_set4_new, y_set5_new), axis=0)\n",
    "\n",
    "# print(y_set_2.shape)\n",
    "\n",
    "# # Combine arrays along axis 0 (vertical stacking)\n",
    "# X_set_1 = np.concatenate((X_set1, X_set2, X_set3, X_set4, X_set5), axis=0)\n",
    "\n",
    "# print(X_set_1.shape)\n",
    "\n",
    "# np.save('X_set_6.npy', X_set_2)\n",
    "# np.save('y_set_6.npy', y_set_2)\n",
    "\n",
    "\n",
    "# np.save('X_test_6.npy', X_test_2)\n",
    "# np.save('y_test_6.npy', y_test_2)\n",
    "\n",
    "# loaded_data = np.load('/Users/rob/Desktop/Semester data/Sem 4 S23/CS6340 Prof Haas/Volunteer Project/Incremental Learning/datasets/X_set_1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31aa789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('X_test_4.npy', X_test_2)\n",
    "# np.save('y_test_4.npy', y_test_2)\n",
    "# np.save('X_test_new.npy', X_test_new)\n",
    "# np.save('y_test_new.npy', y_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa8aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #pd.set_option('display.max_colwidth', None)\n",
    "# np.set_printoptions(threshold=np.inf)\n",
    "# display(X)\n",
    "# display(y)\n",
    "\n",
    "# type(X_set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b39c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Splitting the data in training and testing set.\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = None)\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)\n",
    "\n",
    "# print(X_test.shape)\n",
    "# print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea0df17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_set_1 = np.load('/Users/rob/Desktop/Semester data/Sem 4 S23/CS6340 Prof Haas/Volunteer Project/Incremental Learning/datasets/X_set_6.npy')\n",
    "y_set_1 = np.load('/Users/rob/Desktop/Semester data/Sem 4 S23/CS6340 Prof Haas/Volunteer Project/Incremental Learning/datasets/y_set_6.npy')\n",
    "\n",
    "\n",
    "X_set_2 = np.load('/Users/rob/Desktop/Semester data/Sem 4 S23/CS6340 Prof Haas/Volunteer Project/Incremental Learning/datasets/X_set_5.npy')\n",
    "y_set_2 = np.load('/Users/rob/Desktop/Semester data/Sem 4 S23/CS6340 Prof Haas/Volunteer Project/Incremental Learning/datasets/y_set_5.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d6eedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_1 = np.load('/Users/rob/Desktop/Semester data/Sem 4 S23/CS6340 Prof Haas/Volunteer Project/Incremental Learning/datasets/X_test_5.npy')\n",
    "y_test_1 = np.load('/Users/rob/Desktop/Semester data/Sem 4 S23/CS6340 Prof Haas/Volunteer Project/Incremental Learning/datasets/y_test_5.npy')\n",
    "\n",
    "X_test_2 = np.load('/Users/rob/Desktop/Semester data/Sem 4 S23/CS6340 Prof Haas/Volunteer Project/Incremental Learning/datasets/X_test_6.npy')\n",
    "y_test_2 = np.load('/Users/rob/Desktop/Semester data/Sem 4 S23/CS6340 Prof Haas/Volunteer Project/Incremental Learning/datasets/y_test_6.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e318341",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_set_1.shape)\n",
    "# print(X_test_1.shape)\n",
    "\n",
    "print(X_set_2.shape)\n",
    "# print(y_test_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce1d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_set_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ed6290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_function(pred_solution, test_solution):\n",
    "    # Compare each pair of rows\n",
    "    elementwise_comparison = (pred_solution == test_solution)\n",
    "\n",
    "    # Count the number of equal elements in each pair\n",
    "    equal_counts = np.sum(elementwise_comparison, axis=1)\n",
    "\n",
    "#     print(\"Number of equal elements in each pair of rows:\")\n",
    "#     print(equal_counts)\n",
    "\n",
    "    average = np.sum(equal_counts, axis = 0) / (pred_solution.shape[0] * pred_solution.shape[1])\n",
    "    \n",
    "    return average\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f589b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def accuracy_function(pred_solution, test_solution):\n",
    "#     # Compare each pair of rows\n",
    "#     elementwise_comparison = (pred_solution == test_solution)\n",
    "\n",
    "#     # Count the number of equal elements in each pair\n",
    "#     equal_counts = np.sum(elementwise_comparison, axis=1)\n",
    "\n",
    "#     print(\"Number of equal elements in each pair of rows:\")\n",
    "#     print(equal_counts)\n",
    "#     frac = np.divide(equal_counts, pred_solution.shape[1] )\n",
    "\n",
    "#     average = np.sum(frac, axis = 0) / (pred_solution.shape[0])\n",
    "    \n",
    "#     return average\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0321d188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_gpus():\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0],'GPU')\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1500)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec95959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential, load_model\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_shape=(20,), activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# \t# Compile model\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(30, input_dim=20, kernel_initializer='he_uniform', activation='relu'))\n",
    "# model.add(Dense(10, activation='sigmoid'))\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507674af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the classifier.\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the classifier\n",
    "clf = MultiOutputClassifier(DecisionTreeClassifier(random_state=42, max_depth = 16, min_samples_leaf=4, min_samples_split = 16\n",
    "                                                    ))\n",
    "\n",
    "# clf = MultiOutputClassifier(DecisionTreeClassifier(random_state=42))\n",
    "\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_set_1, y_set_1)\n",
    "\n",
    "\n",
    "score = clf.score(X_set_1, y_set_1)\n",
    "print('Train Accuracy:', score)\n",
    "\n",
    "score = clf.score(X_test_1, y_test_1)\n",
    "print('Test Accuracy:', score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a075d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predictions using classifier\n",
    "y_pred_1 = clf.predict(X_test_1)\n",
    "y_pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2058f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_function(y_pred_1, y_test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827d40dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions using classifier\n",
    "y_pred_1 = clf.predict(X_test_2)\n",
    "y_pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065800bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16224c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # building the classifier.\n",
    "\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.multioutput import MultiOutputClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Define the classifier\n",
    "# clf1 = MultiOutputClassifier(DecisionTreeClassifier(random_state=42, max_depth = 16, min_samples_split = 16, min_samples_leaf=4))\n",
    "\n",
    "\n",
    "# # Train the classifier\n",
    "# clf1.fit(X_set_1, y_set_1)\n",
    "\n",
    "# # Test the classifier\n",
    "# y_pred_1 = clf1.predict(X_test_1)\n",
    "\n",
    "# score = clf1.score(X_set_1, y_set_1)\n",
    "# print(' Train Accuracy:', score)\n",
    "# score = clf1.score(X_test_1, y_test_1)\n",
    "# print('Test Accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892080d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6291e580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2868e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Define the classifier\n",
    "clf = MultiOutputClassifier(DecisionTreeClassifier(random_state=42))\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'estimator__criterion': ['gini'],\n",
    "    'estimator__max_depth': [4,5,6, 7, 8, 9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "    'estimator__min_samples_leaf': [1,2,3,4,5,6,7,8,9,10,11,12],\n",
    "    'estimator__min_samples_split': [10,11,12,13,14,15,16,17,18,19,20,22,23,24,25]\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, verbose=2 )\n",
    "grid_search.fit(X_set_2, y_set_2)\n",
    "\n",
    "# Get the best estimator and its hyperparameters\n",
    "best_clf = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# # Test the best classifier\n",
    "# y_pred = best_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fa4be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62b3b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_clf.score(X_set_2, y_set_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dabe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_set_2 = X_set_2.astype(str)\n",
    "X_set_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14b7321",
   "metadata": {},
   "source": [
    "# classifier 2 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a05bd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the classifier.\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the classifier\n",
    "clf = MultiOutputClassifier(DecisionTreeClassifier(random_state=42, max_depth = 13,min_samples_leaf=9, min_samples_split =25,\n",
    "                                                    ))\n",
    "\n",
    "# clf = MultiOutputClassifier(DecisionTreeClassifier(random_state=42))\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_set_2, y_set_2)\n",
    "\n",
    "\n",
    "score = clf.score(X_set_2, y_set_2)\n",
    "print('Test Accuracy:', score)\n",
    "score = clf.score(X_test_2, y_test_2)\n",
    "print('Test Accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0888c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # building the classifier.\n",
    "\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.multioutput import MultiOutputClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Define the classifier\n",
    "# clf2 = MultiOutputClassifier(DecisionTreeClassifier(random_state=42, max_depth = 14, min_samples_split = 16,\n",
    "#                                                     min_samples_leaf=4))\n",
    "\n",
    "# # # Define the classifier\n",
    "# # clf = MultiOutputClassifier(DecisionTreeClassifier(random_state=42))\n",
    "\n",
    "# # Train the classifier\n",
    "# clf2.fit(X_set_2, y_set_2)\n",
    "\n",
    "# # Test the classifier\n",
    "# \n",
    "\n",
    "# score = clf2.score(X_set_2, y_set_2)\n",
    "# print(' Train Accuracy:', score)\n",
    "# score = clf2.score(X_test_2, y_test_2)\n",
    "# print('Test Accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af6179c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_2 = clf.predict(X_test_2)\n",
    "y_pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d5e4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_function(y_pred_2, y_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c7a176",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b7f28b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8094f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  x3 = α∙x1+(1-α)∙ x2\n",
    "y_pred_3_1 = 0.1 * y_pred_1 + (1 - 0.1)* y_pred_2\n",
    "y_pred_3_2 = 0.2 * y_pred_1 + (1 - 0.2)* y_pred_2\n",
    "y_pred_3_3 = 0.3 * y_pred_1 + (1 - 0.3)* y_pred_2\n",
    "y_pred_3_4 = 0.4 * y_pred_1 + (1 - 0.3)* y_pred_2\n",
    "y_pred_3_5 = 0.5 * y_pred_1 + (1 - 0.5)* y_pred_2\n",
    "y_pred_3_6 = 0.6 * y_pred_1 + (1 - 0.6)* y_pred_2\n",
    "y_pred_3_7 = 0.7 * y_pred_1 + (1 - 0.7)* y_pred_2\n",
    "y_pred_3_8 = 0.8 * y_pred_1 + (1 - 0.8)* y_pred_2\n",
    "y_pred_3_9 = 0.9 * y_pred_1 + (1 - 0.9)* y_pred_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6837c807",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_3_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffc711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# checking if value is greater than threshold 0.5\n",
    "y_pred_3_1 = np.where(y_pred_3_1 > 0.5, 1, 0)\n",
    "y_pred_3_2 = np.where(y_pred_3_2 > 0.5, 1, 0)\n",
    "y_pred_3_3 = np.where(y_pred_3_3 > 0.5, 1, 0)\n",
    "y_pred_3_4 = np.where(y_pred_3_4 > 0.5, 1, 0)\n",
    "y_pred_3_5 = np.where(y_pred_3_5 > 0.5, 1, 0)\n",
    "y_pred_3_6 = np.where(y_pred_3_6 > 0.5, 1, 0)\n",
    "y_pred_3_7 = np.where(y_pred_3_7 > 0.5, 1, 0)\n",
    "y_pred_3_8 = np.where(y_pred_3_8 > 0.5, 1, 0)\n",
    "y_pred_3_9 = np.where(y_pred_3_9 > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099f4f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_1 =  np.sum(np.all(y_pred_3_1 == y_test_2, axis=1)) \n",
    "# count_2 =  np.sum(np.all(y_pred_3_2 == y_test_2, axis=1))\n",
    "# count_3 =  np.sum(np.all(y_pred_3_3 == y_test_2, axis=1)) \n",
    "# count_4 =  np.sum(np.all(y_pred_3_4 == y_test_2, axis=1))\n",
    "# count_5 =  np.sum(np.all(y_pred_3_5 == y_test_2, axis=1)) \n",
    "# count_6 =  np.sum(np.all(y_pred_3_6 == y_test_2, axis=1)) \n",
    "# count_7 =  np.sum(np.all(y_pred_3_7 == y_test_2, axis=1))\n",
    "# count_8 =  np.sum(np.all(y_pred_3_8 == y_test_2, axis=1)) \n",
    "# count_9 =  np.sum(np.all(y_pred_3_9 == y_test_2, axis=1))\n",
    "\n",
    "\n",
    "# count_1 =  np.sum(np.all(y_pred_3_1 == y_test_4, axis=1)) \n",
    "# count_2 =  np.sum(np.all(y_pred_3_2 == y_test_4, axis=1))\n",
    "# count_3 =  np.sum(np.all(y_pred_3_3 == y_test_4, axis=1)) \n",
    "# count_4 =  np.sum(np.all(y_pred_3_4 == y_test_4, axis=1))\n",
    "# count_5 =  np.sum(np.all(y_pred_3_5 == y_test_4, axis=1)) \n",
    "# count_6 =  np.sum(np.all(y_pred_3_6 == y_test_4, axis=1)) \n",
    "# count_7 =  np.sum(np.all(y_pred_3_7 == y_test_4, axis=1))\n",
    "# count_8 =  np.sum(np.all(y_pred_3_8 == y_test_4, axis=1)) \n",
    "# count_9 =  np.sum(np.all(y_pred_3_9 == y_test_4, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfcdaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total = y_test_2.shape[0]\n",
    "\n",
    "# total = y_test_4.shape[0]\n",
    "\n",
    "# accuracy_vec = []\n",
    "# accuracy_vec.append( count_1 / total )\n",
    "# accuracy_vec.append( count_2 / total )\n",
    "# accuracy_vec.append( count_3 / total )\n",
    "# accuracy_vec.append( count_4 / total )\n",
    "# accuracy_vec.append( count_5 / total )\n",
    "# accuracy_vec.append( count_6 / total )\n",
    "# accuracy_vec.append( count_7 / total )\n",
    "# accuracy_vec.append( count_8 / total )\n",
    "# accuracy_vec.append( count_9 / total )\n",
    "# accuracy_vec\n",
    "\n",
    "accuracy_vec = []\n",
    "accuracy_vec.append( accuracy_function(y_pred_3_1, y_test_2) )\n",
    "accuracy_vec.append( accuracy_function(y_pred_3_2, y_test_2) )\n",
    "accuracy_vec.append( accuracy_function(y_pred_3_3, y_test_2) )\n",
    "accuracy_vec.append( accuracy_function(y_pred_3_4, y_test_2) )\n",
    "accuracy_vec.append( accuracy_function(y_pred_3_5, y_test_2) )\n",
    "accuracy_vec.append( accuracy_function(y_pred_3_6, y_test_2) )\n",
    "accuracy_vec.append( accuracy_function(y_pred_3_7, y_test_2) )\n",
    "accuracy_vec.append( accuracy_function(y_pred_3_8, y_test_2) )\n",
    "accuracy_vec.append( accuracy_function(y_pred_3_9, y_test_2) )\n",
    "accuracy_vec\n",
    "\n",
    "# accuracy_vec = []\n",
    "# accuracy_vec.append( accuracy_function(y_pred_3_1, y_test_4) )\n",
    "# accuracy_vec.append( accuracy_function(y_pred_3_2, y_test_4) )\n",
    "# accuracy_vec.append( accuracy_function(y_pred_3_3, y_test_4) )\n",
    "# accuracy_vec.append( accuracy_function(y_pred_3_4, y_test_4) )\n",
    "# accuracy_vec.append( accuracy_function(y_pred_3_5, y_test_4) )\n",
    "# accuracy_vec.append( accuracy_function(y_pred_3_6, y_test_4) )\n",
    "# accuracy_vec.append( accuracy_function(y_pred_3_7, y_test_4) )\n",
    "# accuracy_vec.append( accuracy_function(y_pred_3_8, y_test_4) )\n",
    "# accuracy_vec.append( accuracy_function(y_pred_3_9, y_test_4) )\n",
    "# accuracy_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fea41b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(count_1)\n",
    "# print(count_2)\n",
    "# print(count_3)\n",
    "# print(count_4)\n",
    "# print(count_5)\n",
    "# print(count_6)\n",
    "# print(count_7)\n",
    "# print(count_8)\n",
    "# print(count_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b823cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "alpha_vec = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8,  0.9]\n",
    "\n",
    "plt.plot(alpha_vec, accuracy_vec, marker='o')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Test Accuracy vs. alpha values')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bff3403",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2045d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create two sample arrays (replace with your arrays)\n",
    "array1 = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]])\n",
    "\n",
    "array2 = np.array([[1, 2, 3],\n",
    "                   [4, 2, 6],\n",
    "                   [7, 8, 9]])\n",
    "\n",
    "# Compare each pair of rows\n",
    "matches_count = np.sum(np.all(array1 == array2, axis=1))\n",
    "\n",
    "print(\"Number of matching rows:\", matches_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e78d50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Define the classifier\n",
    "clf = MultiOutputClassifier(DecisionTreeClassifier(random_state=42))\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'estimator__criterion': ['gini'],\n",
    "    'estimator__max_depth': [14, 15, 16, 17, 18],\n",
    "    'estimator__min_samples_split': [14, 15, 16, 17, 18],\n",
    "    'estimator__min_samples_leaf': [2, 3, 4, 5, 6]\n",
    "    \n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_seafrch fd= GridSearchCV(clf, param_grid, verbose=2)\n",
    "grid_search.fit(X_set_2, y_set_2)\n",
    "\n",
    "# # Get the best estimator and its hyperparameters\n",
    "# best_clf = grid_search.best_estimator_\n",
    "# best_params = grid_search.best_params_\n",
    "\n",
    "# Test the best classifier\n",
    "# y_pred = best_clf.predict(X_test_2)\n",
    "os.system(f\"afplay {notification_sound}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f31b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best estimator and its hyperparameters\n",
    "best_clf = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "score = best_clf.score(X_set_2, y_set_2)\n",
    "print(' Train Accuracy:', score)\n",
    "score = best_clf.score(X_test_2, y_test_2)\n",
    "print('Test Accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0417ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0556d2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "secenario_1_sol = clf.predict(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92b5c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a54af07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # building the classifier.\n",
    "\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.multioutput import MultiOutputClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from skmultiflow.trees import HoeffdingTreeClassifier\n",
    "\n",
    "# # Define the classifier\n",
    "# clf = MultiOutputClassifier(HoeffdingTreeClassifier())\n",
    "\n",
    "# # Train the classifier\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# # Test the classifier\n",
    "# y_pred = clf.predict(X_test)\n",
    "\n",
    "# score = clf.score(X_train, y_train)\n",
    "# print(' Train Accuracy:', score)\n",
    "# score = clf.score(X_test, y_test)\n",
    "# print('Test Accuracy:', score)\n",
    "\n",
    "# for x_, y_ in zip(X,y):\n",
    "#     print(x_)\n",
    "#     print(y_)\n",
    "# print(X_train)\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdaa731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_set_12 = np.concatenate((X_set_1, X_set1_2, X_set2_2), axis=0)\n",
    "# y_set_12 = np.concatenate((y_set_1, y_set1_2, y_set2_2), axis=0)\n",
    "X_set_12 = np.concatenate((X_set_1), axis=0)\n",
    "y_set_12 = np.concatenate((y_set_1), axis=0)\n",
    "X_set_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa989526",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c74c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_set_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da083374",
   "metadata": {},
   "source": [
    "## Hoeffding Adaptive decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eb0d94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from river.datasets import synth\n",
    "from river import evaluate\n",
    "from river import metrics\n",
    "from river import tree\n",
    "from river import multioutput\n",
    "from river import drift\n",
    "\n",
    "\n",
    "\n",
    "# ht_model = tree.HoeffdingTreeClassifier(\n",
    "#     max_depth = 16,\n",
    "#     split_criterion = 'gini',\n",
    "#     grace_period=100,\n",
    "#     delta=1e-5 #,\n",
    "#     #nominal_attributes=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17','18', '19', '20']\n",
    "# )\n",
    "\n",
    "\n",
    "# ht_model = multioutput.ClassifierChain(\n",
    "#     model=tree.HoeffdingAdaptiveTreeClassifier( grace_period=100,\n",
    "#                                                 #drift_detector=drift.binary.DDM(),\n",
    "#                                                 #max_depth = 16,\n",
    "#                                                 #split_criterion = 'gini',\n",
    "#                                                 #nominal_attributes=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "#                                                 nominal_attributes=['Att1', 'Att2', 'Att3', 'Att4', 'Att5', 'Att6', 'Att7', 'Att8', 'Att9', 'Att10', 'Att11', 'Att12', 'Att13', 'Att14', 'Att15', 'Att16', 'Att17','Att18', 'Att19', 'Att20']\n",
    "# ))\n",
    "\n",
    "ht_model = multioutput.ClassifierChain(\n",
    "    model=tree.iSOUPTreeRegressor(\n",
    "    \n",
    "))\n",
    "\n",
    "n_samples = 0\n",
    "correct_cnt = 0\n",
    "\n",
    "\n",
    "for xi, yi in zip(X_set1_1,y_set1_1):\n",
    "    #xi = dict(enumerate(xi))  \n",
    "    #yi = dict(enumerate(yi))\n",
    "    \n",
    "    # as features should be in the form of dictionary\n",
    "    xi = {f\"Att{index + 1}\": value for index, value in enumerate(xi)}\n",
    "    \n",
    "    yi = {(index + 1): value == 1 for index, value in enumerate(yi)}\n",
    "    \n",
    "    #yi = yi[0]\n",
    "    \n",
    "    print(n_samples, end = \" \") \n",
    "    \n",
    "    #y_pred = ht_model.predict_one(xi)\n",
    "    \n",
    "    if(n_samples == 5):\n",
    "        print(xi)\n",
    "        print(yi)\n",
    "\n",
    "   \n",
    "    ht_model = ht_model.learn_one(xi, yi)\n",
    "    n_samples = n_samples + 1\n",
    "\n",
    "\n",
    "print(\"training completed . ...\", end = \" \") \n",
    "os.system(f\"afplay {notification_sound}\")\n",
    "#metric = metrics.Accuracy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f402f9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_arr1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2adcff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_arr1\n",
    "\n",
    "# accuracy_arr1 =  [0.2887, 0.38502, 0.46644, 0.51914, 0.54324]\n",
    "# accuracy_arr2 =  [0.21838, 0.4058, 0.43754, 0.47082, 0.49346]\n",
    "\n",
    "\n",
    "# accuracy_arr2 =  [0.33812, 0.38794, 0.42944, 0.44972, 0.469]\n",
    "# accuracy_arr1 = [0.39084, 0.41236, 0.44722, 0.4761, 0.52682]\n",
    "\n",
    "\n",
    "\n",
    "# accuracy_arr1 =  [0.32092, 0.42144, 0.51282, 0.51024, 0.53542]\n",
    "# accuracy_arr2 =  [0.34202, 0.41472, 0.43708, 0.46606, 0.47888]\n",
    "\n",
    "\n",
    "# accuracy_arr2 =  [0.32962, 0.41138, 0.43526, 0.46308, 0.49114]\n",
    "# accuracy_arr1 =  [0.33266, 0.41292, 0.47982, 0.51108, 0.54498]\n",
    "\n",
    "\n",
    "# [0.5211,\n",
    "#  0.2351,\n",
    "#  0.34848,\n",
    "#  0.40204,\n",
    "#  0.28252,\n",
    "#  0.43472,\n",
    "#  0.27866,\n",
    "#  0.47664,\n",
    "#  0.0856,\n",
    "#  0.23956,\n",
    "#  0.39152,\n",
    "#  0.44502,\n",
    "#  0.20216]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50764652",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_arr2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce982ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436b2fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def retrain_model(X_set_temp, y_set_temp, model):\n",
    "    \n",
    "#     for xi, yi in zip(X_set_temp, y_set_temp):\n",
    "#         xi = {f\"Att{index + 1}\": value for index, value in enumerate(xi)}\n",
    "#         yi = {(index + 1): value == 1 for index, value in enumerate(yi)}\n",
    "#         model = model.learn_one(xi, yi)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6730fd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain_model(X_set2_1, y_set2_1, ht_model)\n",
    "# accuracy_test.append(get_accuracy(X_test_1, y_test_1))\n",
    "\n",
    "# retrain_model(X_set3_1, y_set3_1, ht_model)\n",
    "# accuracy_test.append(get_accuracy(X_test_1, y_test_1))\n",
    "\n",
    "# retrain_model(X_set4_1, y_set4_1, ht_model)\n",
    "# accuracy_test.append(get_accuracy(X_test_1, y_test_1))\n",
    "\n",
    "# retrain_model(X_set5_1, y_set5_1, ht_model)\n",
    "# accuracy_test.append(get_accuracy(X_test_1, y_test_1))\n",
    "\n",
    "# os.system(f\"afplay {notification_sound}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dfd0e9",
   "metadata": {},
   "source": [
    "## re-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7e352f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "n_samples = 0\n",
    "for xi, yi in zip(X_set5_2,y_set5_2):\n",
    "#     xi = dict(enumerate(xi))         # as features should be in the form of dictionary\n",
    "#     yi = dict(enumerate(yi))\n",
    "    \n",
    "    \n",
    "    xi = {f\"Att{index + 1}\": value for index, value in enumerate(xi)}\n",
    "    \n",
    "    yi = {(index + 1): value == 1 for index, value in enumerate(yi)}\n",
    "    \n",
    "    #yi = yi[0]\n",
    "    \n",
    "    print(n_samples, end = \" \") \n",
    "    \n",
    "    #y_pred = ht_model.predict_one(xi)\n",
    "    \n",
    "#     if(n_samples == 5):\n",
    "#         print(y_pred)\n",
    "#         print(xi)\n",
    "\n",
    "   \n",
    "    ht_model = ht_model.learn_one(xi, yi)\n",
    "    n_samples = n_samples + 1\n",
    "    \n",
    "print(\"retraining done.. .\", end = \" \")\n",
    "os.system(f\"afplay {notification_sound}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6992324e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_accuracy(X_test_temp, y_test_temp):\n",
    "    \n",
    "#     n_samples = 0\n",
    "#     correct_cnt = 0\n",
    "\n",
    "#     for  xi, yi  in zip(X_test_temp,y_test_temp):\n",
    "    \n",
    "#         xi = {f\"Att{index + 1}\": value for index, value in enumerate(xi)}\n",
    "    \n",
    "#         yi = {(index + 1): value == 1 for index, value in enumerate(yi)}\n",
    "    \n",
    "#         y_pred = ht_model.predict_one(xi)\n",
    "    \n",
    "# #        print(n_samples, end = \" \") \n",
    "    \n",
    "# #         if(n_samples == 5):\n",
    "# #             print(y_pred)\n",
    "# #             print(xi)\n",
    "        \n",
    "#         if(yi == y_pred):\n",
    "#             correct_cnt += 1\n",
    "\n",
    "#         n_samples = n_samples + 1\n",
    "    \n",
    "#     print(\"accuracy calculated \")\n",
    "    \n",
    "#     return (correct_cnt / n_samples)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f22698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(get_accuracy(X_test_1, y_test_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b257d25",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e68063e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_samples = 0\n",
    "correct_cnt = 0\n",
    "\n",
    "# Train the estimator with the samples provided by the data stream\n",
    "\n",
    "for  xi, yi  in zip(X_test_1,y_test_1):\n",
    "    \n",
    "#     xi = dict(enumerate(xi)) \n",
    "#     yi = dict(enumerate(yi))\n",
    "    \n",
    "    xi = {f\"Att{index + 1}\": value for index, value in enumerate(xi)}\n",
    "    \n",
    "    yi = {(index + 1): value == 1 for index, value in enumerate(yi)}\n",
    "    \n",
    "    y_pred = ht_model.predict_one(xi)\n",
    "    \n",
    "    print(n_samples, end = \" \") \n",
    "    \n",
    "    if(n_samples == 5):\n",
    "        print(y_pred)\n",
    "        print(xi)\n",
    "        \n",
    "    if(yi == y_pred):\n",
    "        correct_cnt += 1\n",
    "\n",
    "    n_samples = n_samples + 1    \n",
    "    \n",
    "    \n",
    "    \n",
    " # Display results\n",
    "print('{} samples analyzed.'.format(n_samples))\n",
    "print('accuracy: {}'.format(correct_cnt / n_samples))\n",
    "accuracy_arr1.append(correct_cnt / n_samples)\n",
    "os.system(f\"afplay {notification_sound}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a999ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Python list\n",
    "# python_list = [1, 2, 3, 4, 5]\n",
    "\n",
    "# # Convert to 1D NumPy array\n",
    "# numpy_array = np.array(python_list)\n",
    "\n",
    "# print(numpy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2702cea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd274de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "\n",
    "# # Example 1\n",
    "# numbers = [1, 2, 3, 4]\n",
    "\n",
    "\n",
    "# for size in range(4, 0, -1):\n",
    "#     result = itertools.combinations(numbers, size)\n",
    "#     for combination in result:\n",
    "#         print(combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb8b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# accuracy_arr1 =  [0.2887, 0.38502, 0.46644, 0.51914, 0.54324]\n",
    "# accuracy_arr2 =  [0.21838, 0.4058, 0.43754, 0.47082, 0.49346]\n",
    "\n",
    "\n",
    "# accuracy_arr2 =  [0.33812, 0.38794, 0.42944, 0.44972, 0.469]\n",
    "# accuracy_arr1 = [0.39084, 0.41236, 0.44722, 0.4761, 0.52682]\n",
    "\n",
    "\n",
    "# accuracy_arr1 =  [0.32092, 0.42144, 0.51282, 0.51024, 0.53542]\n",
    "# accuracy_arr2 =  [0.34202, 0.41472, 0.43708, 0.46606, 0.47888]\n",
    "\n",
    "\n",
    "# accuracy_arr2 =  [0.32962, 0.41138, 0.43526, 0.46308, 0.49114]\n",
    "# accuracy_arr1 =  [0.33266, 0.41292, 0.47982, 0.51108, 0.54498]\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "input_rows = [20000, 40000, 60000, 80000, 100000]\n",
    "\n",
    "# plt.subplot(3, 1, 1)\n",
    "\n",
    "plt.plot(input_rows, accuracy_arr1, input_rows, accuracy_arr2, marker='o')\n",
    "\n",
    "# plt.title('arrangment_1')\n",
    "\n",
    "# plt.subplot(3, 1, 2) \n",
    "# plt.plot(input_rows, , marker='x')\n",
    "# plt.title('arrangment_2')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Training Data Rows')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.legend(['arrangement_1', 'arrangement_2'])\n",
    "plt.title('arrangement_1 then arrangement_2')\n",
    "\n",
    "# Display the plot\n",
    "# plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84922c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
